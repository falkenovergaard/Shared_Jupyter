{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1\n",
    "Introduced in 1950 by Richard Hamming, the Hamming code is basically a means of counteracting errors in the transfer of data in binary bit format. In the case of Hamming himself, the errors originated from the a punchcard reader at his workplace. Yet, this method can in principle be used for errorcorrection in data transfer, no matter the medium.\n",
    "The Hamming code makes use of the concepts of dot-product from linear algebra and parity bits in combination. The idea is this: take a 4-bit piece of data, you wish to transfer. This can be seen as a 4x1 vector. Multiply this vector by a 7x4 so-called _\"generator-matrix\"_, to create a 7-bit _code word_. This 7-bit code word now contains both the original 4 bits of data along with 3 parity bits, that can be used for error correction, once data has been transfered. \n",
    "The code below contains a method that, when supplied with a 4-bit data-string constructs a 7-bit code word, using a Hamming Code (named _G matrix_ in the code, short for generator matrix). The details of the method will be explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7-bit code_word [0, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import random\n",
    "\n",
    "# Method to convert a 4-bit message in to a 7-bit code word, \n",
    "# adding 3 parity bits in the process\n",
    "def encoder(message):\n",
    "    \n",
    "    #This is the generator/encoding matrix\n",
    "    G_matrix = [[1,0,1,1],\n",
    "                [1,1,0,1],\n",
    "                [0,0,0,1],\n",
    "                [1,1,1,0],\n",
    "                [0,0,1,0],\n",
    "                [0,1,0,0],\n",
    "                [1,0,0,0]]\n",
    "    \n",
    "    # Variable to hold the 7-bit codeword\n",
    "    code_word = []\n",
    "    \n",
    "    # For-loop to test the number of rows in the matrix\n",
    "    for i in range(len(G_matrix)):\n",
    "        # Variable to hold the dot-product\n",
    "        count = 0\n",
    "        # Nested for-loop to calculate the dot-product of every row multiplicated by the 4-bit message\n",
    "        for x in range(len(message)):\n",
    "            count += message[x] * G_matrix[i][x]\n",
    "        # Every dot-product is appended to the code_word variable, creating the 7-bit code_word.\n",
    "        code_word.append(count%2)\n",
    "    \n",
    "    return(code_word)\n",
    "\n",
    "print('7-bit code_word',encoder([1,0,1,0]))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the encoder on the 4 bits __[1,0,1,0]__, the resulting 7-bit code word is __[0,1,0,0,1,0,1]__.To understand the whole concept of Hamming codes, and why the 7-bit code word looks the way it does, it is necessary to understand the concept of parity bits.\n",
    "### Parity bits\n",
    "These bits do not contain parts of the original data, but rather meta data in the form of _\"data about the data\"_. This means, that a parity bit is an indication of wether the number of 1's in a piece of data is even or odd. Working with even parities, means that a parity bit will be 1, if the number of 1's in piece of data is odd, as this makes the sum of all 1's even (odd number + 1 = even number.\n",
    "In the code above, 3 parity bits are introduced in positions 1,2 and 4 of the 7-bit code word. This can be seen, as rows 1,2 and 4 in the G_matrix have 3 1' each, but in different positions. What this means is, that all the parity bits look at 3 positions in the original 4 pieces of data, and checks, whether they are even or odd. As an example, the first parity bit (first row of G-matrix) has the form __[1,0,1,1]__, which means that is \"look\" for 1's in positions 1,3,4. Our data is __[1,0,1,0]__, which means we get a dot-product of 2 in this instance, as both vectors have a 1 in positions 1 and 3. And so the parity bit in position 1 is a zero, as the number of 1's in the bits looked at is already even. In the code this check for even/oddd is done by using the _modulus-operator_ with 2 (%2).\n",
    "The following table illustrates which parity bits (P) are looking at which data bits (D), and which positions the different bits are placed in, in the final 7-bit code word:\n",
    "<img src=\"attachment:image.png\" width=\"400\">\n",
    "\n",
    "The 4 remaining bits of the 7-bit codeword in positions 3,5,6,7 are basically just a mirroring of the original 4 bits of data. It is worth noting (as is also illustrated in the above table), that the G-matrix used in this case actually turns the original 4 bits of data around. This can be seen by the way, that the 7th row of the G-matrix has a 1 in it's first position. This means that it \"looks\" at the first position of the data. The 6'th row has a 1 in it's 3rd position and so on.\n",
    "\n",
    "Encoding a 4 bits of data in to a 7 bit code word is only really a clever thing to do, if the data is at risk of incurring errors in the form of flipped bits. To demonstrate how the use of a Hamming code can effectively find and correct such a flipped bit error, the following code is a method, that introduces a random flipped bit to our code word __[0, 1, 0, 0, 1, 0, 1]__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original code word: [0, 1, 0, 0, 1, 0, 1]\n",
      "Code word w. error: [1, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Method introducing a random 1 bit error (bit-flip) to the code_word,\n",
    "# immitating a noisy data-transfer\n",
    "def noisy_channel (code_word):\n",
    "    \n",
    "    # Variable to hold the code word with the 1-bit error\n",
    "    err_code_word = code_word[:]\n",
    "    # Variable to hold a random location of a 1-bit error\n",
    "    bit_flip_location = random.randint(0,len(code_word)-1)\n",
    "    \n",
    "    # If-loop to flip the bit at the random location of error\n",
    "    if code_word[bit_flip_location] == 1:\n",
    "        err_code_word[bit_flip_location] = 0\n",
    "    else:\n",
    "        err_code_word[bit_flip_location] = 1\n",
    "    \n",
    "    return (err_code_word)\n",
    "print('Original code word:', encoder([1,0,1,0]))\n",
    "err_code_word = noisy_channel(encoder([1,0,1,0]))\n",
    "print('Code word w. error:', err_code_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the above code, it should hopefully be apparent, that a bit in one of the 7 positions has been flipped. This is obviously a problem, as the data is not representative of the original data any more. There is of course a chance, that the flipped bit is one of the parity bits, and as such, the original 4 bits of data are still correct. But had we sent the 4 bits of data without 3 parity bits, a flipped bit would inevitably have been a bit of the original data, and in that case we would not have any means of finding and correcting this error by using the parity bits.\n",
    "The following code introduces a method, that looks for errors and correct these, if any are present. This is done by making use of a so-caled _parity check matrix_ (named H_matrix in the code), looking at the 3 parity bits for information on whether an error is present in the data, and if so, in which location it is, so the bit in this position can be switched back.\n",
    "The details of the code are explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original code word:            [0, 1, 0, 0, 1, 0, 1]\n",
      "Code word w. error:            [1, 1, 0, 0, 1, 0, 1]\n",
      "Code word w. error correction: [0, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Method for correcting the 1-bit error introduced to the original 7-bit code word\n",
    "def error_correction (err_code_word):\n",
    "    \n",
    "    # This is the parity-check matrix\n",
    "    H_Matrix = [[1,0,1,0,1,0,1],\n",
    "                [0,1,1,0,0,1,1],\n",
    "                [0,0,0,1,1,1,1]]\n",
    "    \n",
    "    # Variable to hold the location of the flipped bit (bit error)\n",
    "    error_location = 0\n",
    "    # Variable to hold the code word with the erroneous bit flipped back\n",
    "    corrected_code_word = err_code_word[:]\n",
    "    \n",
    "    # For-loop to test the number of rows in the matrix\n",
    "    for i in range(len(H_Matrix)):\n",
    "        # Variable to hold the dot-product\n",
    "        count = 0\n",
    "        # Nested for-loop to calculate the dot-product of every row multiplicated by the 7-bit code word\n",
    "        for x in range(len(err_code_word)):\n",
    "            if err_code_word[x] * H_Matrix[i][x] == 1:\n",
    "                count += 1\n",
    "        # If-loop testing, whether the dot-product is even or not. \n",
    "        #With an uneven dot-product, the binary value of the parity-bit is added to the error-location\n",
    "        if count%2 == 1:\n",
    "            error_location += 2**i\n",
    "    \n",
    "    # If loop testing if the error loaction is 0 (no error).\n",
    "    # In case it is not, the bit at the error location will be flipped back\n",
    "    if error_location != 0:\n",
    "        if err_code_word[error_location-1] == 1:\n",
    "            corrected_code_word[error_location-1] = 0\n",
    "        else: \n",
    "            corrected_code_word[error_location-1] = 1\n",
    "    \n",
    "    return (corrected_code_word)\n",
    "\n",
    "print('Original code word:           ', encoder([1,0,1,0]))\n",
    "print('Code word w. error:           ', err_code_word)\n",
    "print('Code word w. error correction:', error_correction(err_code_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code, location and correcting the random bit-error in principle works just like the operation of encoding the 4-bit message. The H-matrix, being a 3x7 matrix, when multiplied by our 7x1 code word vector, results in a 3x1 vector representing the results of a parity-check of the 3 parity bits in the code word. If we look at the first row of the H-matrix __[1,0,1,0,1,0,1]__, it has 1's in position 1,3,5 and 7. Position 1 is the position of the parity bit itself, and if we look back at the table above (subsection on __parity bits__), we see that the first parity bit does indeed look to the data-bits in positions 3,5,7. As the Hamming code is working with even parity bits, the dot product of looking at the 4 positions should be an even number (once again the _modulus-operator_ is used with 2 (%2) to make this check in the code). If the parity check is even, the modulus-operation will result in a 0, indicating that the sum of 1's is still even, and that no single bits have been flipped in any of the 4 positions 1,3,5,7, as the dot-product would otherwise have been odd.\n",
    "This means, that in case there are no errors in the data, the result of multiplying the H-matrix by the code word will be a [0,0,0] vector. In our case an error has been introduced, as 1 bit has been flipped. And this is where the Hamming code gets really clever. If the flipped bit is one of the parity bits, it is quite obvious, as the parity bit will now be giving the wrong information (saying even, when the number of one's being looked at is odd or the other way around). If, on the other hand, the bit-error is in a bit of the original data, all bits of data are \"covered\" by at least 2 parity bits (3 parity bits for data-bit 1). This means, that when a data-bit is flipped, 2 parity bits will actually be giving the wrong information (saying even, when the number of one's being looked at is odd or the other way around). Knowing which 2 parity bits are wrong, we also know which data-bit has been flipped, as it must be the one, shared by the 2 parity bits, that are \"lying\". This information is simply used to flip back the bit in the position corresponding position (a parity bit is 1 parity bit is wrong, and a data-bit if 2 or 3 parity-bits are wrong.\n",
    "The following code completes the last step of utilizing the Hamming code, by decoding the error corrected 7-bit code word back into the original 4-bit data-string by utilizing a _decoding matrix_ (named R_matrix in the code). The details of the code are explained below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 4-bit message:        [1, 0, 1, 0]\n",
      "Original code word:            [0, 1, 0, 0, 1, 0, 1]\n",
      "Code word w. error:            [1, 1, 0, 0, 1, 0, 1]\n",
      "Code word w. error correction: [0, 1, 0, 0, 1, 0, 1]\n",
      "Decoded code word:             [1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Method for convert a 7-bit codeword back into a 4-bit message, \n",
    "# removing 3 parity bits in the process\n",
    "def decoder(code_word):\n",
    "    \n",
    "    # This is the decoding matrix\n",
    "    R_matrix = [[0,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,1,0],\n",
    "                [0,0,0,0,1,0,0],\n",
    "                [0,0,1,0,0,0,0]]\n",
    "    \n",
    "    # Variable to hold the decoded 4-bit message\n",
    "    message = []\n",
    "    \n",
    "    # For-loop to test the number of rows in the matrix\n",
    "    for i in range(len(R_matrix)):\n",
    "        # Variable to hold the dot-product\n",
    "        count = 0\n",
    "        # Nested for-loop to calculate the dot-product of every row multiplicated by the 7-bit code_word\n",
    "        for x in range(len(code_word)):\n",
    "            if code_word[x] * R_matrix[i][x] == 1:\n",
    "                count += 1\n",
    "        # Every dot-product is appended to the message variable, \n",
    "        # recreating the original 4-bit message\n",
    "        message.append(count)\n",
    "    \n",
    "    return(message)\n",
    "\n",
    "print('Original 4-bit message:        [1, 0, 1, 0]')\n",
    "print('Original code word:           ', encoder([1,0,1,0]))\n",
    "print('Code word w. error:           ', err_code_word)\n",
    "print('Code word w. error correction:', error_correction(err_code_word))\n",
    "print('Decoded code word:            ', decoder(error_correction(err_code_word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoding process is basically performing the opossite of the encoding process. This time we are multiplying the 4x7 H_matrix by the 7x1 code word. This will result in a 4x1 vector correctly representing the original data string. Looking at the 4 rows of the H-matrix, it becomes quite clear, that each one is looking at just 1 position in the 7-bit code word. The first row is only looking at the 7th position, which is where the 1 bit of the original 4-bit data-string was placed (as explained, the data-string was reversed due to the way the Hamming code used in this paper is constructed. By the design of the H-matrix in this way, the data is now turned back around, and the 3 parity bits are sorted out. What we are left with is the original 4 bits of data, all correct, even though they passed through a noisy channel, that introduced an error to one of the bits.\n",
    "\n",
    "It is worth noting, that the 7x4 Hamming code is only effective at correcting 1 bit errors. The result of looking at the parity bits will not be distinguishable between 1 or 2 bit errors, yet with 2 flipped bits, it will not be possible to deduct their position, and as such, any attempt at correcting 2 bit errors will yield a wrong result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3\n",
    "The following code illustrates the overall functionality of all methods with 4 widely different 4-bit messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The original message:                             [0, 0, 0, 1]\n",
      "The 7-bit code_word of the message:               [1, 1, 1, 0, 0, 0, 0]\n",
      "With a random bit flip the code word becomes:     [1, 1, 1, 1, 0, 0, 0]\n",
      "Code word after error detection and correction:   [1, 1, 1, 0, 0, 0, 0]\n",
      "The decoded 4 bit message after error-correction: [0, 0, 0, 1]\n",
      "\n",
      "The original message:                             [0, 1, 1, 0]\n",
      "The 7-bit code_word of the message:               [1, 1, 0, 0, 1, 1, 0]\n",
      "With a random bit flip the code word becomes:     [1, 1, 0, 0, 1, 0, 0]\n",
      "Code word after error detection and correction:   [1, 1, 0, 0, 1, 1, 0]\n",
      "The decoded 4 bit message after error-correction: [0, 1, 1, 0]\n",
      "\n",
      "The original message:                             [1, 1, 1, 0]\n",
      "The 7-bit code_word of the message:               [0, 0, 0, 1, 1, 1, 1]\n",
      "With a random bit flip the code word becomes:     [0, 0, 1, 1, 1, 1, 1]\n",
      "Code word after error detection and correction:   [0, 0, 0, 1, 1, 1, 1]\n",
      "The decoded 4 bit message after error-correction: [1, 1, 1, 0]\n",
      "\n",
      "The original message:                             [1, 1, 1, 1]\n",
      "The 7-bit code_word of the message:               [1, 1, 1, 1, 1, 1, 1]\n",
      "With a random bit flip the code word becomes:     [1, 1, 1, 1, 1, 1, 0]\n",
      "Code word after error detection and correction:   [1, 1, 1, 1, 1, 1, 1]\n",
      "The decoded 4 bit message after error-correction: [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "message = [0,0,0,1]\n",
    "print('\\nThe original message:                            ', message)\n",
    "print('The 7-bit code_word of the message:              ', encoder(message))\n",
    "print('With a random bit flip the code word becomes:    ', noisy_channel(encoder(message)))\n",
    "print('Code word after error detection and correction:  ', error_correction(noisy_channel(encoder(message))))\n",
    "print('The decoded 4 bit message after error-correction:', decoder(error_correction(noisy_channel(encoder(message)))))\n",
    "\n",
    "message = [0,1,1,0]\n",
    "print('\\nThe original message:                            ', message)\n",
    "print('The 7-bit code_word of the message:              ', encoder(message))\n",
    "print('With a random bit flip the code word becomes:    ', noisy_channel(encoder(message)))\n",
    "print('Code word after error detection and correction:  ', error_correction(noisy_channel(encoder(message))))\n",
    "print('The decoded 4 bit message after error-correction:', decoder(error_correction(noisy_channel(encoder(message)))))\n",
    "\n",
    "message = [1,1,1,0]\n",
    "print('\\nThe original message:                            ', message)\n",
    "print('The 7-bit code_word of the message:              ', encoder(message))\n",
    "print('With a random bit flip the code word becomes:    ', noisy_channel(encoder(message)))\n",
    "print('Code word after error detection and correction:  ', error_correction(noisy_channel(encoder(message))))\n",
    "print('The decoded 4 bit message after error-correction:', decoder(error_correction(noisy_channel(encoder(message)))))\n",
    "\n",
    "message = [1,1,1,1]\n",
    "print('\\nThe original message:                            ', message)\n",
    "print('The 7-bit code_word of the message:              ', encoder(message))\n",
    "print('With a random bit flip the code word becomes:    ', noisy_channel(encoder(message)))\n",
    "print('Code word after error detection and correction:  ', error_correction(noisy_channel(encoder(message))))\n",
    "print('The decoded 4 bit message after error-correction:', decoder(error_correction(noisy_channel(encoder(message)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
